# Mode: train or inference
mode: train

# Training settings
training:
  batch_size: 24
  duration: 1
  num_steps: 100
  max_epochs: 1000
  optimizer: prodigy
  learning_rate: 1
  seed: 191
  grad_accum: 1
  grad_clip: 1.0
  target_sources:
    - vocals
  precision: bf16-mixed
  aligned: false
  augment: false
  validation_steps: 2

#Model specific settings
#Type can be: BSRoformer, MagSep

#model:
#  type: "BSRoformer"
#  n_fft: 2048
#  hop_length: 512
#  layers: 1
#  mask_layers: 1
#  dropout: 0.1
#  embed_dim: 64
#  freqs_per_bands: [ 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 12, 12, 12, 12, 12, 12, 12, 12, 24, 24, 24, 24, 24, 24, 24, 24, 48, 48, 48, 48, 48, 48, 48, 48, 128, 128 ]

model:
  type: "MagSep"
  n_fft: 2048
  hop_length: 512
  layers: 1
  splits: 32


# Paths for different modes
paths:
  # Where to save checkpoint files
  checkpoints: "/media/phil/Big/AudioSep/checkpoints"

  # Dataset location
  dataset: "/media/phil/E65864AD58647DE5/AudioSep/combined"

  # Optional: Where to save validation outputs for listening
  validation: "/home/phil/AudioSep/validation"

  # Optional: Resume training or inference from a checkpoint
  #  resume_from: "/media/phil/Big/AudioSep/checkpoints/last-v172.ckpt"

  # Optional: Inference mode input folder, this must be used with resume_from option
  # inference_input: "/home/user/AudioSep/datasets/musdb18hq_flac/test"

# Logging and debugging
logging:
  wandb:
    enabled: false
    save_code: true # Uploads all code in the model directory to wandb
  validate_every: 10 # Validation loss / sdr metric interval (0 to disable)
  debug_every: 0 # Debug visualization interval (0 to disable)
  debug_steps: 1

inference:
  batch_size: 1
  duration: 10
  steps: 10

